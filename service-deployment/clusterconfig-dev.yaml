# Copyright (c) Microsoft Corporation
# All rights reserved.
#
# MIT License
#
# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
# documentation files (the "Software"), to deal in the Software without restriction, including without limitation
# the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
# to permit persons to whom the Software is furnished to do so, subject to the following conditions:
# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED *AS IS*, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
# BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
# DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

clusterID: your_cluster_id


clusterinfo:

  # HDFS, zookeeper data path
  dataPath: "/datastorage"

  # PAI data root path
  paiPath: "/var/pai"

  # Choose proper nvidia driver version from this url http://www.nvidia.com/object/linux-amd64-display-archive.html
  nvidia_drivers_version: 384.111

  # static docker-version
  # https://download.docker.com/linux/static/stable/x86_64/docker-17.06.2-ce.tgz
  # Docker client used by hadoop NM (node manager) to launch Docker containers (e.g., of a deep learning job) in the host env.
  dockerverison: 17.12.0

  # the docker registry to store docker images that contain system services like frameworklauncher, hadoop, etc.
  dockerregistryinfo:

    # If public, please fill it the same as your username
    docker_namespace: leinao

    # E.g., gcr.io. If publicï¼Œfill docker_registry_domain with word "public"
    # docker_registry_domain: public
    docker_registry_domain: 192.168.2.212:5000
    # If the docker registry doesn't require authentication, please leave docker_username and docker_password empty
    docker_username: leinao
    docker_password: leinaoAI2018

    docker_tag: latest

    # The name of the secret in kubernetes will be created in your cluster
    # Must be lower case, e.g., regsecret.
    secretname: regsecret

  # hadoop config information
  hadoopinfo:
    # If custom_hadoop_binary_path is None, script will download a standard version of hadoop binary for you
    # hadoop-version
    # http://archive.apache.org/dist/hadoop/common/hadoop-2.7.2/hadoop-2.7.2.tar.gz
    custom_hadoop_binary_path: /home/ubuntu/hadoop-2.7.2.tar.gz
    hadoopversion: 2.7.2
    configmapname: hadoop-configuration
    hadoop_vip: 192.168.2.216

  frameworklauncher:
    frameworklauncher_vip: 192.168.2.216
    frameworklauncher_port: 9086

  restserverinfo:
    # path for rest api server src dir
    src_path: ../rest-server/
    # uri for frameworklauncher webservice
    webservice_uri: http://192.168.2.216:9086
    # uri for hdfs
    hdfs_uri: hdfs://192.168.2.216:9000
    # port for rest api server
    server_port: 9186
    # secret for signing authentication tokens, e.g., "Hello PAI!"
    jwt_secret: your_jwt_secret
    # authentication database file path relative to PAI data path
    lowdb_path: "rest-server/user.db.json"
    # database admin username
    lowdb_admin: cluster_admin
    # database admin password
    lowdb_passwd: cluster_admin
    ftpservice_uri: http://192.168.2.216:5001
    webhdfs_uri: http://192.168.2.216:50070

  # The config for web portal
  webportalinfo:
    # root url of the rest server
    rest_server_uri: http://192.168.2.216:9186
    # root url of the prometheus server
    prometheus_uri: http://192.168.6.105:9090
    # root url of the grafana portal
    grafana_uri: http://192.168.2.216:3000
    # root url of the k8s dashboard
    k8s_dashboard_uri: http://192.168.2.216:9090
    # root url of the k8s apiserver
    k8s_api_server_uri: http://192.168.2.216:8080
    # port for webportal
    server_port: 9286

  # The config for Grafana
  grafanainfo:  
    # The address of the grafana to connect to
    grafana_url: http://192.168.2.216
    # port for grafana
    grafana_port: 3000

  # The config for monitor service
  prometheusinfo:
    # The address of the prometheus to connect to
    prometheus_url: http://192.168.6.105
    # port for prometheus port
    prometheus_port: 9090
    # port for node exporter
    node_exporter_port: 9100
    # cadvisor port
    cadvisor_port: 8089

  pyloninfo:
    # root url of the rest server
    rest_server_uri: http://192.168.2.216:9186
    # root url of the k8s apiserver
    k8s_api_server_uri: http://192.168.2.216:8080
    # root url of the webhdfs api server
    webhdfs_uri: http://192.168.2.216:50070
    # root url of the prometheus server
    prometheus_uri: http://192.168.6.105:9090
    # root url of the k8s dashboard
    k8s_dashboard_uri: http://192.168.2.216:9090
    # root url of grafana
    grafana_uri: http://192.168.2.216:3000
    # root url of the web portal
    webportal_uri: http://192.168.2.216:9286
    # port of pylon
    port: 81
# The detail machine type information in your cluster, each machine type has an entry here
# An Azure VM example
machineinfo:

  NC24R8:
    mem: 224
    gpu:
    # type: gpu{type}
      type: teslak80
      count: 8
    cpu:
      vcore: 24
    dataFolder: "/mnt"
    # Note: Up to now, the only supported os version is Ubuntu16.04. Please do not change it here.
    os: ubuntu16.04

  NC24R4:
    mem: 64
    gpu:
    # type: gpu{type}
      type: teslak80
      count: 4
    cpu:
      vcore: 24
    dataFolder: "/mnt"
    # Note: Up to now, the only supported os version is Ubuntu16.04. Please do not change it here.
    os: ubuntu16.04

  D8SV3:
    mem: 31
    cpu:
      vcore: 8
    dataFolder: "/mnt"
    # Note: Up to now, the only supported os version is Ubuntu16.04. Pls don't change it here.
    os: ubuntu16.04


# The machine list in your cluster
# An example
machinelist:
  # Replace your own hostname here.
  cpu216:
    # recommend to be the same as host IP
    nodename: 192.168.2.216
    # Replace your own machine type here
    machinetype: D8SV3 
    # Replace your own IP here.
    ip: 192.168.2.216
    # all hadooprole: master will install zk, please specify a unique zkid for each node. Begin at "1".
    zkid: "1"
    # hdfsrole:   master or worker
    # yarnrole:   master or worker
    # zookeeper:  "true"   or not set this value
    # Note: if zookeeper is set, you should set zkid in this machine.
    # jobhistory: "true"   or not set this value
    # grafana: "true"   or not set this value
    hdfsrole: master
    yarnrole: master
    zookeeper: "true"
    jobhistory: "true"
    launcher: "true"
    restserver: "true"
    webportal: "true"
    grafana: "true"
    pylon: "true"
    node-exporter: "true"
 
  gpu105:
    nodename: 192.168.6.105
    machinetype: NC24R8
    ip: 192.168.6.105
    hdfsrole: worker
    yarnrole: worker
    prometheus: "true"
    node-exporter: "true"
